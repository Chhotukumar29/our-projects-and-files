{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1efd40c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, re\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import regexp_tokenize, TweetTokenizer, RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7631766f",
   "metadata": {},
   "outputs": [],
   "source": [
    "flist = os.listdir(r'C:\\Users\\chhot\\Dropbox\\BlackCoffer\\StopWords')\n",
    "\n",
    "with open('StopWords.txt', 'w') as outfile:\n",
    "    for file in flist:\n",
    "        with open(file) as infile:\n",
    "            for line in infile:\n",
    "                line = line.split(' | ')[0]+'\\n'\n",
    "                outfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "24d75216",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table('StopWords.txt', header=None, skip_blank_lines=True, encoding='windows-1252', names=['SW'])\n",
    "StopWords = df['SW'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b63a39aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>146</td>\n",
       "      <td>https://insights.blackcoffer.com/blockchain-fo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>147</td>\n",
       "      <td>https://insights.blackcoffer.com/the-future-of...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>148</td>\n",
       "      <td>https://insights.blackcoffer.com/big-data-anal...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>149</td>\n",
       "      <td>https://insights.blackcoffer.com/business-anal...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>150</td>\n",
       "      <td>https://insights.blackcoffer.com/challenges-an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     URL_ID                                                URL  \\\n",
       "0        37  https://insights.blackcoffer.com/ai-in-healthc...   \n",
       "1        38  https://insights.blackcoffer.com/what-if-the-c...   \n",
       "2        39  https://insights.blackcoffer.com/what-jobs-wil...   \n",
       "3        40  https://insights.blackcoffer.com/will-machine-...   \n",
       "4        41  https://insights.blackcoffer.com/will-ai-repla...   \n",
       "..      ...                                                ...   \n",
       "109     146  https://insights.blackcoffer.com/blockchain-fo...   \n",
       "110     147  https://insights.blackcoffer.com/the-future-of...   \n",
       "111     148  https://insights.blackcoffer.com/big-data-anal...   \n",
       "112     149  https://insights.blackcoffer.com/business-anal...   \n",
       "113     150  https://insights.blackcoffer.com/challenges-an...   \n",
       "\n",
       "     POSITIVE SCORE  NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \\\n",
       "0               NaN             NaN             NaN                 NaN   \n",
       "1               NaN             NaN             NaN                 NaN   \n",
       "2               NaN             NaN             NaN                 NaN   \n",
       "3               NaN             NaN             NaN                 NaN   \n",
       "4               NaN             NaN             NaN                 NaN   \n",
       "..              ...             ...             ...                 ...   \n",
       "109             NaN             NaN             NaN                 NaN   \n",
       "110             NaN             NaN             NaN                 NaN   \n",
       "111             NaN             NaN             NaN                 NaN   \n",
       "112             NaN             NaN             NaN                 NaN   \n",
       "113             NaN             NaN             NaN                 NaN   \n",
       "\n",
       "     AVG SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS  FOG INDEX  \\\n",
       "0                    NaN                          NaN        NaN   \n",
       "1                    NaN                          NaN        NaN   \n",
       "2                    NaN                          NaN        NaN   \n",
       "3                    NaN                          NaN        NaN   \n",
       "4                    NaN                          NaN        NaN   \n",
       "..                   ...                          ...        ...   \n",
       "109                  NaN                          NaN        NaN   \n",
       "110                  NaN                          NaN        NaN   \n",
       "111                  NaN                          NaN        NaN   \n",
       "112                  NaN                          NaN        NaN   \n",
       "113                  NaN                          NaN        NaN   \n",
       "\n",
       "     AVG NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT  WORD COUNT  \\\n",
       "0                                 NaN                 NaN         NaN   \n",
       "1                                 NaN                 NaN         NaN   \n",
       "2                                 NaN                 NaN         NaN   \n",
       "3                                 NaN                 NaN         NaN   \n",
       "4                                 NaN                 NaN         NaN   \n",
       "..                                ...                 ...         ...   \n",
       "109                               NaN                 NaN         NaN   \n",
       "110                               NaN                 NaN         NaN   \n",
       "111                               NaN                 NaN         NaN   \n",
       "112                               NaN                 NaN         NaN   \n",
       "113                               NaN                 NaN         NaN   \n",
       "\n",
       "     SYLLABLE PER WORD  PERSONAL PRONOUNS  AVG WORD LENGTH  \n",
       "0                  NaN                NaN              NaN  \n",
       "1                  NaN                NaN              NaN  \n",
       "2                  NaN                NaN              NaN  \n",
       "3                  NaN                NaN              NaN  \n",
       "4                  NaN                NaN              NaN  \n",
       "..                 ...                ...              ...  \n",
       "109                NaN                NaN              NaN  \n",
       "110                NaN                NaN              NaN  \n",
       "111                NaN                NaN              NaN  \n",
       "112                NaN                NaN              NaN  \n",
       "113                NaN                NaN              NaN  \n",
       "\n",
       "[114 rows x 15 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('Output Data Structure.xlsx')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5e6d095e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complex_word_count(word):\n",
    "    word = word.lower()\n",
    "    count = 0\n",
    "    vowels = \"aeiou\"\n",
    "    if word[0] in vowels:\n",
    "        count += 1\n",
    "    for index in range(1, len(word)):\n",
    "        if word[index] in vowels and word[index-1] not in vowels:\n",
    "            count += 1\n",
    "    if count == 0:\n",
    "        count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e17c0c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = r'C:\\Users\\chhot\\Dropbox\\BlackCoffer\\text files'\n",
    "path2 = r\"C:\\Users\\chhot\\Dropbox\\BlackCoffer\\text file cleaned\"\n",
    "\n",
    "tfiles = os.listdir(path1)\n",
    "wrdcnt = []\n",
    "cwrdcnt = []\n",
    "twac = []\n",
    "for i in df['URL_ID'].values:\n",
    "    with open(r'{}\\{}.{}'.format(path1,i,'txt'),encoding='utf-8') as infile,open(r'{}\\{}.{}'.format(path2,i,'txt'),'w',encoding='utf-8') as outfile:\n",
    "        text = word_tokenize(infile.read())\n",
    "        wrdcnt.append(len(text))\n",
    "        cwcnt=0\n",
    "        for wrd in text:\n",
    "            if complex_word_count(wrd)>2:\n",
    "                cwcnt+=1\n",
    "        cwrdcnt.append(cwcnt)\n",
    "        filtext = [txt for txt in text if not txt in StopWords]\n",
    "        outfile.write(' '.join(filtext))\n",
    "        twac.append(len(filtext))\n",
    "\n",
    "df['wrdcnt'] = wrdcnt\n",
    "df['COMPLEX WORD COUNT'] = cwrdcnt\n",
    "df['twac'] = twac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6ecdc4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "path3 = r\"C:\\Users\\chhot\\Dropbox\\BlackCoffer\\MasterDictionary\" \n",
    "path4 = r\"C:\\Users\\chhot\\Dropbox\\BlackCoffer\\MasterDictionaryCleaned\"\n",
    "\n",
    "dfiles = os.listdir(path3)\n",
    "for dfile in dfiles:\n",
    "    with open(r'{}\\{}'.format(path3,dfile), encoding='windows-1252') as infile, open(r'{}\\{}'.format(path4,dfile), 'w', encoding='windows-1252') as outfile:\n",
    "        text1 = word_tokenize(infile.read())\n",
    "        filtext1 = [txt for txt in text1 if not txt in StopWords]\n",
    "        outfile.write(' '.join(filtext1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f3a28b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'{}\\{}'.format(path4,'positive-words.txt'), encoding='windows-1252') as file:\n",
    "    PositiveWords = word_tokenize(file.read())\n",
    "\n",
    "with open(r'{}\\{}'.format(path4,'negative-words.txt'), encoding='windows-1252') as file:\n",
    "    NegativeWords = word_tokenize(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bfa5a90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pscore = []\n",
    "for i in df['URL_ID'].values:\n",
    "    ps = 0\n",
    "    with open(r'{}\\{}.{}'.format(path2,i,'txt'), encoding='utf-8') as f:\n",
    "        for txt in word_tokenize(f.read()):\n",
    "            for txt1 in PositiveWords:\n",
    "                if txt == txt1: ps+=1\n",
    "    pscore.append(ps)\n",
    "df['POSITIVE SCORE'] = pscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "40867837",
   "metadata": {},
   "outputs": [],
   "source": [
    "nscore = []\n",
    "for i in df['URL_ID'].values:\n",
    "    ns = 0\n",
    "    with open(r'{}\\{}.{}'.format(path2,i,'txt'), encoding='utf-8') as f:\n",
    "        for txt in word_tokenize(f.read()):\n",
    "            for txt1 in NegativeWords:\n",
    "                if txt == txt1: ns-=1\n",
    "    nscore.append(-ns)\n",
    "df['NEGATIVE SCORE'] = nscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6152f6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['POLARITY SCORE']=round((df['POSITIVE SCORE']-df['NEGATIVE SCORE'])/((df['POSITIVE SCORE']+df['NEGATIVE SCORE'])+0.000001),2)\n",
    "df['SUBJECTIVITY SCORE']=round((df['POSITIVE SCORE']+df['NEGATIVE SCORE'])/((df['twac'])+0.000001),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "09eec331",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentcnt = []\n",
    "for i in df['URL_ID'].values:\n",
    "    with open(r'{}\\{}.{}'.format(path1,i,'txt'),encoding='utf-8') as infile:\n",
    "        sent = sent_tokenize(infile.read())\n",
    "        sentcnt.append(len(sent))\n",
    "        \n",
    "df['sentcnt'] = sentcnt        \n",
    "df['AVG SENTENCE LENGTH']=round(df['wrdcnt']/df['sentcnt'],2)\n",
    "df['PERCENTAGE OF COMPLEX WORDS']=round(df['COMPLEX WORD COUNT']/df['wrdcnt'],2)\n",
    "df['FOG INDEX']=round(0.4*(df['AVG SENTENCE LENGTH']+df['PERCENTAGE OF COMPLEX WORDS']),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b0ff412e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AVG NUMBER OF WORDS PER SENTENCE']=round(df['wrdcnt']/df['sentcnt'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f2fb73e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "NLTK_StopWords = list(set(stopwords.words('english')))\n",
    "\n",
    "tfiles = os.listdir(path1)\n",
    "personal_nouns = []\n",
    "for i in df['URL_ID'].values:\n",
    "    with open(r'{}\\{}.{}'.format(path1,i,'txt'),encoding='utf-8') as f:\n",
    "        text2 = word_tokenize(f.read())\n",
    "        filtext2 = [txt for txt in text2 if not txt in NLTK_StopWords and txt not in ['I', 'we','my', 'ours', 'us', 'US']]\n",
    "        personal_nouns.append(len(filtext2))\n",
    "\n",
    "df['PERSONAL PRONOUNS'] = personal_nouns       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5f6e2659",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (3510431610.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [82]\u001b[1;36m\u001b[0m\n\u001b[1;33m    return tokens\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "personal_nouns = []\n",
    "for i in df['URL_ID'].values:\n",
    "    with open(r'{}\\{}.{}'.format(path1,i,'txt'),encoding='utf-8') as f:\n",
    "        tokens = RegexpTokenizer('[\\w]+')\n",
    "        tokenizer.tokenize('I', 'we','my', 'ours', 'us', 'US') \n",
    "        for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a980eefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def syllable_count(word):\n",
    "    word = word.lower()\n",
    "    count = 0\n",
    "    vowels = \"aeiou\"\n",
    "    if word[0] in vowels:\n",
    "        count += 1\n",
    "    for index in range(1, len(word)):\n",
    "        if word[index] in vowels and word[index-1] not in vowels:\n",
    "            count += 1\n",
    "    if word.endswith(('es','ed')):\n",
    "        count -= 1\n",
    "    if count == 0:\n",
    "        count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42e5f45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NLTK_StopWords = list(set(stopwords.words('english')))\n",
    "\n",
    "tfiles = os.listdir(path1)\n",
    "WrdCnt = []\n",
    "for i in df['URL_ID'].values:\n",
    "    with open(r'{}\\{}.{}'.format(path1,i,'txt'),encoding='utf-8') as f:\n",
    "        text2 = word_tokenize(f.read())\n",
    "        filtext2 = [txt for txt in text2 if not txt in NLTK_StopWords and txt not in ['?','!',',','.']]\n",
    "        WrdCnt.append(len(filtext2))\n",
    "\n",
    "df['WORD COUNT'] = WrdCnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "164c4748",
   "metadata": {},
   "outputs": [],
   "source": [
    "scl = []\n",
    "for i in df['URL_ID'].values:\n",
    "    with open(r'{}\\{}.{}'.format(path1,i,'txt'),encoding='utf-8') as f:\n",
    "        words = word_tokenize(f.read())\n",
    "        sc = 0\n",
    "        for word in words:\n",
    "            sc += syllable_count(word)\n",
    "    scl.append(sc)\n",
    "\n",
    "df['SYLLABLE PER WORD'] = scl/df['WORD COUNT'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3eb6ba0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['twac','wrdcnt','sentcnt'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c4294d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "awl = []\n",
    "for i in df['URL_ID'].values:\n",
    "    with open(r'{}\\{}.{}'.format(path1,i,'txt'),encoding='utf-8') as f:\n",
    "        words = word_tokenize(f.read())\n",
    "        avgwrdlgth = 0\n",
    "        for word in words:\n",
    "            arpitviansh = len(word)\n",
    "            avgwrdlgth = avgwrdlgth + arpitviansh\n",
    "    awl.append(avgwrdlgth)\n",
    "df['AVG WORD LENGTH'] = (len(word))/(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdea4677",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "72c71f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>63</td>\n",
       "      <td>33</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.08</td>\n",
       "      <td>16.29</td>\n",
       "      <td>0.39</td>\n",
       "      <td>6.67</td>\n",
       "      <td>16.29</td>\n",
       "      <td>487</td>\n",
       "      <td>1076</td>\n",
       "      <td>2.504647</td>\n",
       "      <td>1254</td>\n",
       "      <td>0.001534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>56</td>\n",
       "      <td>38</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.11</td>\n",
       "      <td>10.67</td>\n",
       "      <td>0.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>10.67</td>\n",
       "      <td>239</td>\n",
       "      <td>669</td>\n",
       "      <td>2.375187</td>\n",
       "      <td>856</td>\n",
       "      <td>0.001534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>65</td>\n",
       "      <td>35</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.09</td>\n",
       "      <td>13.28</td>\n",
       "      <td>0.39</td>\n",
       "      <td>5.47</td>\n",
       "      <td>13.28</td>\n",
       "      <td>443</td>\n",
       "      <td>944</td>\n",
       "      <td>2.557203</td>\n",
       "      <td>1125</td>\n",
       "      <td>0.001534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>56</td>\n",
       "      <td>24</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.09</td>\n",
       "      <td>9.87</td>\n",
       "      <td>0.28</td>\n",
       "      <td>4.06</td>\n",
       "      <td>9.87</td>\n",
       "      <td>257</td>\n",
       "      <td>747</td>\n",
       "      <td>2.369478</td>\n",
       "      <td>907</td>\n",
       "      <td>0.001534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>50</td>\n",
       "      <td>23</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.07</td>\n",
       "      <td>13.18</td>\n",
       "      <td>0.31</td>\n",
       "      <td>5.40</td>\n",
       "      <td>13.18</td>\n",
       "      <td>336</td>\n",
       "      <td>917</td>\n",
       "      <td>2.343511</td>\n",
       "      <td>1087</td>\n",
       "      <td>0.001534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL  POSITIVE SCORE  \\\n",
       "0      37  https://insights.blackcoffer.com/ai-in-healthc...              63   \n",
       "1      38  https://insights.blackcoffer.com/what-if-the-c...              56   \n",
       "2      39  https://insights.blackcoffer.com/what-jobs-wil...              65   \n",
       "3      40  https://insights.blackcoffer.com/will-machine-...              56   \n",
       "4      41  https://insights.blackcoffer.com/will-ai-repla...              50   \n",
       "\n",
       "   NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  AVG SENTENCE LENGTH  \\\n",
       "0              33            0.31                0.08                16.29   \n",
       "1              38            0.19                0.11                10.67   \n",
       "2              35            0.30                0.09                13.28   \n",
       "3              24            0.40                0.09                 9.87   \n",
       "4              23            0.37                0.07                13.18   \n",
       "\n",
       "   PERCENTAGE OF COMPLEX WORDS  FOG INDEX  AVG NUMBER OF WORDS PER SENTENCE  \\\n",
       "0                         0.39       6.67                             16.29   \n",
       "1                         0.28       4.38                             10.67   \n",
       "2                         0.39       5.47                             13.28   \n",
       "3                         0.28       4.06                              9.87   \n",
       "4                         0.31       5.40                             13.18   \n",
       "\n",
       "   COMPLEX WORD COUNT  WORD COUNT  SYLLABLE PER WORD  PERSONAL PRONOUNS  \\\n",
       "0                 487        1076           2.504647               1254   \n",
       "1                 239         669           2.375187                856   \n",
       "2                 443         944           2.557203               1125   \n",
       "3                 257         747           2.369478                907   \n",
       "4                 336         917           2.343511               1087   \n",
       "\n",
       "   AVG WORD LENGTH  \n",
       "0         0.001534  \n",
       "1         0.001534  \n",
       "2         0.001534  \n",
       "3         0.001534  \n",
       "4         0.001534  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7dedac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
